{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a5d1f5-741f-4fc9-89f0-c5f8913d0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping addon with invalid or excluded ID: {'type': 'cmladdon', 'path': '/runtime-addons/cmladdon-2.0.49-b279', 'spec': '\\nenv:\\n  MLFLOW_TRACKING_URI: cml://localhost\\n  MLFLOW_REGISTRY_URI: cml://localhost\\n  PYTHONPATH: ${PYTHONPATH}:/opt/cmladdons/python/site-customize\\n  R_LIBS_SITE: ${R_LIBS_SITE}:/opt/cmladdons/r/libs\\npaths:\\n  - /opt/cmladdons', 'version': '', 'id': -1}\n",
      "2025-07-16 06:09:36,850\tINFO usage_lib.py:467 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
      "2025-07-16 06:09:36,850\tINFO scripts.py:971 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m10.42.1.212\u001b[22m\n",
      "2025-07-16 06:09:51,998\tSUCC scripts.py:1007 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-07-16 06:09:51,999\tSUCC scripts.py:1008 -- \u001b[32mRay runtime started.\u001b[39m\n",
      "2025-07-16 06:09:51,999\tSUCC scripts.py:1009 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-07-16 06:09:52,000\tINFO scripts.py:1011 -- \u001b[36mNext steps\u001b[39m\n",
      "2025-07-16 06:09:52,000\tINFO scripts.py:1014 -- To add another node to this Ray cluster, run\n",
      "2025-07-16 06:09:52,000\tINFO scripts.py:1017 -- \u001b[1m  ray start --address='10.42.1.212:6379'\u001b[22m\n",
      "2025-07-16 06:09:52,001\tINFO scripts.py:1026 -- To connect to this Ray cluster:\n",
      "2025-07-16 06:09:52,001\tINFO scripts.py:1028 -- \u001b[35mimport\u001b[39m\u001b[26m ray\n",
      "2025-07-16 06:09:52,001\tINFO scripts.py:1029 -- ray\u001b[35m.\u001b[39m\u001b[26minit()\n",
      "2025-07-16 06:09:52,002\tINFO scripts.py:1041 -- To submit a Ray job using the Ray Jobs CLI:\n",
      "2025-07-16 06:09:52,002\tINFO scripts.py:1042 -- \u001b[1m  RAY_ADDRESS='http://127.0.0.1:8100' ray job submit --working-dir . -- python my_script.py\u001b[22m\n",
      "2025-07-16 06:09:52,002\tINFO scripts.py:1051 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html \n",
      "2025-07-16 06:09:52,002\tINFO scripts.py:1055 -- for more information on submitting Ray jobs to the Ray cluster.\n",
      "2025-07-16 06:09:52,002\tINFO scripts.py:1060 -- To terminate the Ray runtime, run\n",
      "2025-07-16 06:09:52,003\tINFO scripts.py:1061 -- \u001b[1m  ray stop\u001b[22m\n",
      "2025-07-16 06:09:52,003\tINFO scripts.py:1064 -- To view the status of the cluster, use\n",
      "2025-07-16 06:09:52,003\tINFO scripts.py:1065 --   \u001b[1mray status\u001b[22m\u001b[26m\n",
      "2025-07-16 06:09:52,003\tINFO scripts.py:1069 -- To monitor and debug Ray, view the dashboard at \n",
      "2025-07-16 06:09:52,003\tINFO scripts.py:1070 --   \u001b[1m127.0.0.1:8100\u001b[22m\u001b[26m\n",
      "2025-07-16 06:09:52,003\tINFO scripts.py:1077 -- \u001b[4mIf connection to the dashboard fails, check your firewall settings and network configuration.\u001b[24m\n",
      "2025-07-16 06:09:52,004\tINFO scripts.py:1181 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
      "2025-07-16 06:09:52,004\tINFO scripts.py:1182 -- This command will now block forever until terminated by a signal.\n",
      "2025-07-16 06:09:52,004\tINFO scripts.py:1185 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, os, time\n",
    "import cml.workers_v1 as workers\n",
    "\n",
    "DASHBOARD_PORT = os.environ['CDSW_READONLY_PORT']\n",
    "DASHBOARD_IP = os.environ['CDSW_IP_ADDRESS']\n",
    "\n",
    "# use num-cpus=0 when start a head node to prevent this node from performing task/actor computation.\n",
    "command = \"ray start --head --block --include-dashboard=true --dashboard-port=$CDSW_READONLY_PORT --num-cpus=0 --num-gpus=0 &\" \n",
    "subprocess.run(command, shell = True, executable=\"/bin/bash\")\n",
    "\n",
    "with open(\"RAY_HEAD_IP\", 'w') as output_file:\n",
    "    output_file.write(DASHBOARD_IP)\n",
    "            \n",
    "ray_head_addr = DASHBOARD_IP + ':6379'\n",
    "ray_url = f\"ray://{DASHBOARD_IP}:10001\" \n",
    "worker_start_cmd = f\"!ray start --block --address={ray_head_addr}\"\n",
    "\n",
    "time.sleep(7)\n",
    "ray_workers = workers.launch_workers(\n",
    "    n=5, \n",
    "    cpu=1, \n",
    "    memory=20,\n",
    "    nvidia_gpu=0,\n",
    "    code=worker_start_cmd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ef3dc5-9861-4146-a684-47c40a9bc3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:11:13,708\tINFO worker.py:1723 -- Connecting to existing Ray cluster at address: 10.42.1.212:6379...\n",
      "2025-07-16 06:11:13,744\tINFO worker.py:1908 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8100 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading '3G_cdr_data.csv' with Ray Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:11:17,345\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_5_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing feature engineering on the entire dataset...\n",
      "\n",
      "Splitting engineered data into training, validation, and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:11:17,549\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_5_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:11:17,551\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_5_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV] -> AllToAllOperator[Sort] -> AllToAllOperator[MapBatches(calculate_all_features_for_group)->RandomShuffle] -> AggregateNumRows[AggregateNumRows]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa32da2c3424a9788ddc6c41d54807c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393e451a7f9f470387a672cbf22c212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadCSV->SplitBlocks(107) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28802ba20d684c0b8d1f5aa48b9f4fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd41279a0ab747408f81565f9d2f5b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133af20596ae497f9f7dc53bbfe345ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b1b1e52e8e4c999afaa22e6e4d413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 5:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecb6bb62d694da39bc1a1f5d9329cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(calculate_all_features_for_group)->RandomShuffle 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81147512dd8848a2aee062765f13832a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 7:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d818186ffc42faaa47051156680c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 8:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ba071ecc7e4efaaa0a17417c87f339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- AggregateNumRows 9:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:12:58,133\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_5_0 execution finished in 100.57 seconds\n",
      "2025-07-16 06:12:58,181\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_4_0\n",
      "2025-07-16 06:12:58,202\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_4_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:12:58,204\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_4_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV] -> AllToAllOperator[Sort] -> AllToAllOperator[MapBatches(calculate_all_features_for_group)->RandomShuffle]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3f8cf375834f64bd28b96ad2a63839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5cbf70db5af4830b73f25641a05ac50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadCSV->SplitBlocks(107) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a58bd50116a4c58b5f7d08b4850ad4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca706623aeb24db7ac2beb9d1adaf06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca97fa55d74545c78b46185aa1aebe6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49d3f3acaf1425ca936d7b1e4343bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 5:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccef203e11c84605999e9fa5de80a74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(calculate_all_features_for_group)->RandomShuffle 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073dd4bf6789404dbaba1c5837410587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 7:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1aa8836b874bbaa3991360aaa88973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 8:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:13:51,403\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_4_0 execution finished in 53.19 seconds\n",
      "2025-07-16 06:13:51,722\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_8_0\n",
      "2025-07-16 06:13:51,728\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_8_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:13:51,730\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_8_0: InputDataBuffer[Input] -> AllToAllOperator[RandomShuffle]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b726c4e06b4049e8b99152671ec53647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbbc1bddea54435a0866cfe61279008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0199f98cbdc94e3884a44415d74a3dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d574c0f3a52d40f897515533d0b403fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:13:52,510\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_8_0 execution finished in 0.77 seconds\n",
      "/home/cdsw/.local/lib/python3.10/site-packages/ray/data/dataset.py:1419: UserWarning: Use 'expr' instead of 'fn' when possible for performant filters.\n",
      "  warnings.warn(\n",
      "2025-07-16 06:13:52,627\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_14_0\n",
      "2025-07-16 06:13:52,634\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_14_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:13:52,635\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_14_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)->Filter(<lambda>)] -> AggregateNumRows[AggregateNumRows]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 140000\n",
      "Validation set size: 30000\n",
      "Test set size: 30000\n",
      "\n",
      "Training the XGBoost model with Ray Train...\n",
      "Calculating scale_pos_weight from training data for class imbalance...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8111c48c20b146e3a632709cb826711e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a577c8fc7a60402f9291bd680f132d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(<lambda>)->Filter(<lambda>) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b65492c966a4d8993b96ca8bff43808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- AggregateNumRows 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:13:59,599\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_14_0 execution finished in 6.94 seconds\n",
      "2025-07-16 06:13:59,627\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_16_0\n",
      "2025-07-16 06:13:59,636\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_16_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:13:59,638\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_16_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)->Filter(<lambda>)] -> AggregateNumRows[AggregateNumRows]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec965cab35ca4148a316098069991ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50672c59e2245ec8da7ca98007df6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(<lambda>)->Filter(<lambda>) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7488169692974f828d5b51d18e098d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- AggregateNumRows 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:14:06,058\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_16_0 execution finished in 6.41 seconds\n",
      "2025-07-16 06:14:06,240\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight determined to be: 19.00\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:06 (running for 00:00:00.15)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:11 (running for 00:00:05.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:16 (running for 00:00:10.27)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:21 (running for 00:00:15.32)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:26 (running for 00:00:20.36)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:31 (running for 00:00:25.41)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m - (node_id=ab45681e33ef7beafd12c0910f2ddab578d6fdbf4bd1a9c9e1a44719, ip=10.42.3.24, pid=14183) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m - (node_id=ab45681e33ef7beafd12c0910f2ddab578d6fdbf4bd1a9c9e1a44719, ip=10.42.3.24, pid=14182) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m - (node_id=ab45681e33ef7beafd12c0910f2ddab578d6fdbf4bd1a9c9e1a44719, ip=10.42.3.24, pid=14184) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m - (node_id=ab45681e33ef7beafd12c0910f2ddab578d6fdbf4bd1a9c9e1a44719, ip=10.42.3.24, pid=14185) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m - (node_id=ab45681e33ef7beafd12c0910f2ddab578d6fdbf4bd1a9c9e1a44719, ip=10.42.3.24, pid=14186) world_rank=4, local_rank=4, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:37 (running for 00:00:30.48)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:42 (running for 00:00:35.54)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=14183, ip=10.42.3.24)\u001b[0m [06:14:45] Task [xgboost.ray-rank=00000000]:1e86880754d823b1d300eb9501000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=14527, ip=10.42.3.24)\u001b[0m Registered dataset logger for dataset train_17_0\n",
      "\u001b[36m(SplitCoordinator pid=14527, ip=10.42.3.24)\u001b[0m Starting execution of Dataset train_17_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=14527, ip=10.42.3.24)\u001b[0m Execution plan of Dataset train_17_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> OutputSplitter[split(5, equal=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05dfcf6e773345f8b64dde771d380f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=14527, ip=10.42.3.24) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffefed7298f4c209471551cf88e7117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=14527, ip=10.42.3.24) - MapBatches(<lambda>) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5ce4ab931d463aa9406d2e037f2f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=14527, ip=10.42.3.24) - split(5, equal=True) 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:47 (running for 00:00:40.60)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:52 (running for 00:00:45.66)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=14527, ip=10.42.3.24)\u001b[0m ✔️  Dataset train_17_0 execution finished in 7.22 seconds\n",
      "\u001b[36m(RayTrainWorker pid=14186, ip=10.42.3.24)\u001b[0m [06:14:45] Task [xgboost.ray-rank=00000004]:e714213032229a6ca85e65ac01000000 got rank 4\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(RayTrainWorker pid=14183, ip=10.42.3.24)\u001b[0m Registered dataset logger for dataset dataset_19_0\n",
      "\u001b[36m(SplitCoordinator pid=14528, ip=10.42.3.24)\u001b[0m Starting execution of Dataset valid_18_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=14528, ip=10.42.3.24)\u001b[0m Execution plan of Dataset valid_18_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> OutputSplitter[split(5, equal=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2385172a5042b9a77b1c0cc2011e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=14528, ip=10.42.3.24) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb07707bb1c5424386411bf30c9168ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=14528, ip=10.42.3.24) - MapBatches(<lambda>) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36998d9c34754bc783a6bcff60ecdc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=14528, ip=10.42.3.24) - split(5, equal=True) 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-16 06:14:57 (running for 00:00:50.72)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-16 06:15:02 (running for 00:00:55.77)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=14183, ip=10.42.3.24)\u001b[0m Registered dataset logger for dataset dataset_24_0\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=14528, ip=10.42.3.24)\u001b[0m ✔️  Dataset valid_18_0 execution finished in 8.87 seconds\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [0]\ttrain-logloss:0.43750\ttrain-error:0.00000\tvalid-logloss:0.43750\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [1]\ttrain-logloss:0.29630\ttrain-error:0.00000\tvalid-logloss:0.29630\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [2]\ttrain-logloss:0.20732\ttrain-error:0.00000\tvalid-logloss:0.20732\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [3]\ttrain-logloss:0.14780\ttrain-error:0.00000\tvalid-logloss:0.14780\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [4]\ttrain-logloss:0.10661\ttrain-error:0.00000\tvalid-logloss:0.10661\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [5]\ttrain-logloss:0.07750\ttrain-error:0.00000\tvalid-logloss:0.07750\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [6]\ttrain-logloss:0.05664\ttrain-error:0.00000\tvalid-logloss:0.05664\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [7]\ttrain-logloss:0.04155\ttrain-error:0.00000\tvalid-logloss:0.04155\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [8]\ttrain-logloss:0.03056\ttrain-error:0.00000\tvalid-logloss:0.03056\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [9]\ttrain-logloss:0.02253\ttrain-error:0.00000\tvalid-logloss:0.02253\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:04] [10]\ttrain-logloss:0.01663\ttrain-error:0.00000\tvalid-logloss:0.01663\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [11]\ttrain-logloss:0.01228\ttrain-error:0.00000\tvalid-logloss:0.01228\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [12]\ttrain-logloss:0.00908\ttrain-error:0.00000\tvalid-logloss:0.00908\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [13]\ttrain-logloss:0.00672\ttrain-error:0.00000\tvalid-logloss:0.00672\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [14]\ttrain-logloss:0.00498\ttrain-error:0.00000\tvalid-logloss:0.00498\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [15]\ttrain-logloss:0.00369\ttrain-error:0.00000\tvalid-logloss:0.00369\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [16]\ttrain-logloss:0.00274\ttrain-error:0.00000\tvalid-logloss:0.00274\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [17]\ttrain-logloss:0.00203\ttrain-error:0.00000\tvalid-logloss:0.00203\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [18]\ttrain-logloss:0.00151\ttrain-error:0.00000\tvalid-logloss:0.00151\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [19]\ttrain-logloss:0.00112\ttrain-error:0.00000\tvalid-logloss:0.00112\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [20]\ttrain-logloss:0.00083\ttrain-error:0.00000\tvalid-logloss:0.00083\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [21]\ttrain-logloss:0.00062\ttrain-error:0.00000\tvalid-logloss:0.00062\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [22]\ttrain-logloss:0.00046\ttrain-error:0.00000\tvalid-logloss:0.00046\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [23]\ttrain-logloss:0.00035\ttrain-error:0.00000\tvalid-logloss:0.00035\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [24]\ttrain-logloss:0.00026\ttrain-error:0.00000\tvalid-logloss:0.00026\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [25]\ttrain-logloss:0.00019\ttrain-error:0.00000\tvalid-logloss:0.00019\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [26]\ttrain-logloss:0.00015\ttrain-error:0.00000\tvalid-logloss:0.00015\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [27]\ttrain-logloss:0.00011\ttrain-error:0.00000\tvalid-logloss:0.00011\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [28]\ttrain-logloss:0.00008\ttrain-error:0.00000\tvalid-logloss:0.00009\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:05] [29]\ttrain-logloss:0.00006\ttrain-error:0.00000\tvalid-logloss:0.00007\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [30]\ttrain-logloss:0.00005\ttrain-error:0.00000\tvalid-logloss:0.00005\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [31]\ttrain-logloss:0.00004\ttrain-error:0.00000\tvalid-logloss:0.00004\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [32]\ttrain-logloss:0.00003\ttrain-error:0.00000\tvalid-logloss:0.00003\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [33]\ttrain-logloss:0.00002\ttrain-error:0.00000\tvalid-logloss:0.00002\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [34]\ttrain-logloss:0.00002\ttrain-error:0.00000\tvalid-logloss:0.00002\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [35]\ttrain-logloss:0.00002\ttrain-error:0.00000\tvalid-logloss:0.00002\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [36]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [37]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [38]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [39]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [40]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [41]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [42]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [43]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [44]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [45]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [46]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [47]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [48]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [49]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [50]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [51]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [52]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:06] [53]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [54]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [55]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [56]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [57]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [58]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [59]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [60]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [61]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [62]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [63]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [64]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [65]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-16 06:15:07 (running for 00:01:00.81)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [66]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [67]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [68]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [69]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [70]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [71]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [72]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [73]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [74]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [75]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [76]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [77]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [78]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [79]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:07] [80]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [81]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [82]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [83]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [84]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [85]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [86]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [87]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [88]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [89]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [90]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [91]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [92]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [93]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [94]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [95]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [96]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [97]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [98]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=14109, ip=10.42.3.24)\u001b[0m [06:15:08] [99]\ttrain-logloss:0.00001\ttrain-error:0.00000\tvalid-logloss:0.00001\tvalid-error:0.00000\n",
      "\u001b[36m(RayTrainWorker pid=14183, ip=10.42.3.24)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/cdsw/ray_results/XGBoostTrainer_2025-07-16_06-14-06/XGBoostTrainer_13f6e_00000_0_2025-07-16_06-14-06/checkpoint_000000)\n",
      "2025-07-16 06:15:09,914\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/cdsw/ray_results/XGBoostTrainer_2025-07-16_06-14-06' in 0.0619s.\n",
      "2025-07-16 06:15:09,923\tINFO tune.py:1041 -- Total run time: 63.68 seconds (63.32 seconds for the tuning loop).\n",
      "2025-07-16 06:15:09,989\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_30_0\n",
      "2025-07-16 06:15:09,993\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_30_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:15:09,993\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_30_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-16 06:15:09 (running for 00:01:03.39)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/160 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-16_06-09-36_851382_143/artifacts/2025-07-16_06-14-06/XGBoostTrainer_2025-07-16_06-14-06/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "\n",
      "Model Training Complete.\n",
      "Loading model from the best checkpoint...\n",
      "\n",
      "--- Model Evaluation on Unseen Test Data ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065d7ab5b2ba407baea9b557a8c82274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f797adce27da48aaa621c188fb6ef565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(<lambda>) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13f549350bd4c008961572f472a2766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:15:13,839\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_30_0 execution finished in 3.83 seconds\n",
      "2025-07-16 06:15:13,848\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_29_0\n",
      "2025-07-16 06:15:13,855\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_29_0. Full logs are in /tmp/ray/session_2025-07-16_06-09-36_851382_143/logs/ray-data\n",
      "2025-07-16 06:15:13,856\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_29_0: InputDataBuffer[Input] -> TaskPoolMapOperator[MapBatches(<lambda>)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ac26b453854b4cb313e798ad64c548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02cd3ee5c483454ba9e199322ee0cf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(<lambda>) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 06:15:14,185\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_29_0 execution finished in 0.32 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Test Data):\n",
      "[[28562     0]\n",
      " [    0  1438]]\n",
      "\n",
      "Classification Report (Test Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     28562\n",
      "        True       1.00      1.00      1.00      1438\n",
      "\n",
      "    accuracy                           1.00     30000\n",
      "   macro avg       1.00      1.00      1.00     30000\n",
      "weighted avg       1.00      1.00      1.00     30000\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "total_calls             20.0\n",
      "outgoing_call_ratio     13.0\n",
      "nocturnal_call_ratio     8.0\n",
      "avg_duration             7.0\n",
      "std_duration             7.0\n",
      "dtype: float64\n",
      "\n",
      "Trained XGBoost model saved to 'fraud_detection_model_xgb_ray.json'\n",
      "\n",
      "Process complete in 237.07 seconds.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.data import Dataset\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import os\n",
    "\n",
    "def calculate_all_features_for_group(group_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculates aggregated features for a single user (a group of records).\"\"\"\n",
    "    group_df['is_fraud'] = group_df['is_fraud'].astype(bool)\n",
    "    nocturnal_hours = (group_df['hour_of_day'] >= 22) | (group_df['hour_of_day'] <= 6)\n",
    "    features = {\n",
    "        'total_calls': len(group_df),\n",
    "        'outgoing_call_ratio': (group_df['call_direction'] == 'outgoing').mean(),\n",
    "        'avg_duration': group_df['duration'].mean(),\n",
    "        'std_duration': group_df['duration'].std(),\n",
    "        'nocturnal_call_ratio': nocturnal_hours.mean(),\n",
    "        'mobility': group_df['cell_tower'].nunique(),\n",
    "        'is_fraud': group_df['is_fraud'].iloc[0]\n",
    "    }\n",
    "    return pd.DataFrame([features], index=[group_df['msisdn'].iloc[0]])\n",
    "\n",
    "def feature_engineering_ray(ds: ray.data.Dataset) -> ray.data.Dataset:\n",
    "    \"\"\"Performs feature engineering on the raw call data using Ray Data.\"\"\"\n",
    "    print(\"Performing feature engineering on the entire dataset...\")\n",
    "    # Group by 'msisdn' and apply the feature calculation function to each group.\n",
    "    # This creates one row of features for each unique msisdn.\n",
    "    user_features_ds = ds.groupby('msisdn').map_groups(\n",
    "        calculate_all_features_for_group\n",
    "    )\n",
    "    return user_features_ds\n",
    "\n",
    "def prepare_data(dataset: Dataset) -> tuple[Dataset, Dataset, Dataset]:\n",
    "    \"\"\"Splits the dataset into train (70%), validation (15%), and test (15%) sets.\"\"\"\n",
    "    print(\"\\nSplitting engineered data into training, validation, and test sets...\")\n",
    "    seed = 42\n",
    "    # First, split into training (70%) and the rest (30%)\n",
    "    train_dataset, rest_dataset = dataset.train_test_split(test_size=0.3, shuffle=True, seed=seed)\n",
    "    # Split the rest (30%) evenly into validation (15%) and test (15%)\n",
    "    valid_dataset, test_dataset = rest_dataset.train_test_split(test_size=0.5, shuffle=True, seed=seed)\n",
    "    \n",
    "    print(f\"Train set size: {train_dataset.count()}\")\n",
    "    print(f\"Validation set size: {valid_dataset.count()}\")\n",
    "    print(f\"Test set size: {test_dataset.count()}\")\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "def train_fraud_detection_model_xgb_ray(train_ds: ray.data.Dataset, valid_ds: ray.data.Dataset):\n",
    "    print(\"\\nTraining the XGBoost model with Ray Train...\")\n",
    "\n",
    "    # Fill any potential NaN values that resulted from feature engineering (e.g., std_duration for a single call)\n",
    "    train_ds = train_ds.map_batches(lambda df: df.fillna(0), batch_format=\"pandas\")\n",
    "    valid_ds = valid_ds.map_batches(lambda df: df.fillna(0), batch_format=\"pandas\")\n",
    "\n",
    "    print(\"Calculating scale_pos_weight from training data for class imbalance...\")\n",
    "    num_fraud = train_ds.filter(lambda row: row[\"is_fraud\"] == True).count()\n",
    "    num_non_fraud = train_ds.filter(lambda row: row[\"is_fraud\"] == False).count()\n",
    "\n",
    "    if num_fraud > 0 and num_non_fraud > 0:\n",
    "        scale_pos_weight = num_non_fraud / num_fraud\n",
    "        print(f\"scale_pos_weight determined to be: {scale_pos_weight:.2f}\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(\"Warning: Insufficient classes to calculate scale_pos_weight. Defaulting to 1.0.\")\n",
    "\n",
    "    xgb_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    label_column = 'is_fraud'\n",
    "    \n",
    "    trainer = XGBoostTrainer(\n",
    "        scaling_config=ScalingConfig(num_workers=5, use_gpu=False),\n",
    "        label_column=label_column,\n",
    "        params=xgb_params,\n",
    "        datasets={\"train\": train_ds, \"valid\": valid_ds},\n",
    "        # Add num_boost_round to be comparable with Dask's n_estimators\n",
    "        num_boost_round=100 \n",
    "    )\n",
    "\n",
    "    result = trainer.fit()\n",
    "    print(\"\\nModel Training Complete.\")\n",
    "    \n",
    "    # Use the best checkpoint based on validation loss to get the best model\n",
    "    best_checkpoint = result.get_best_checkpoint(metric=\"valid-logloss\", mode=\"min\")\n",
    "    \n",
    "    if best_checkpoint:\n",
    "        print(\"Loading model from the best checkpoint...\")\n",
    "        with best_checkpoint.as_directory() as checkpoint_dir:\n",
    "            # The model file might be model.xgb or model.ubj depending on the XGBoost version\n",
    "            model_path_ubj = os.path.join(checkpoint_dir, \"model.ubj\")\n",
    "            model_path_xgb = os.path.join(checkpoint_dir, \"model.xgb\")\n",
    "            \n",
    "            model_path = model_path_ubj if os.path.exists(model_path_ubj) else model_path_xgb\n",
    "\n",
    "            if os.path.exists(model_path):\n",
    "                booster = xgb.Booster()\n",
    "                booster.load_model(model_path)\n",
    "                return booster\n",
    "    \n",
    "    print(\"Could not load a model from checkpoint.\")\n",
    "    return None\n",
    "\n",
    "def evaluate_model(booster: xgb.Booster, test_ds: ray.data.Dataset):\n",
    "    \"\"\"Evaluates the trained model on the unseen test dataset.\"\"\"\n",
    "    print(\"\\n--- Model Evaluation on Unseen Test Data ---\")\n",
    "\n",
    "    test_ds = test_ds.map_batches(lambda df: df.fillna(0), batch_format=\"pandas\")\n",
    "\n",
    "    feature_columns = [col for col in test_ds.columns() if col != 'is_fraud']\n",
    "    label_column = 'is_fraud'\n",
    "    \n",
    "    # Convert the test set to a pandas DataFrame for evaluation\n",
    "    test_df = test_ds.to_pandas()\n",
    "    \n",
    "    if test_df.empty:\n",
    "        print(\"Test dataset is empty. Cannot evaluate.\")\n",
    "        return\n",
    "\n",
    "    X_test = test_df[feature_columns]\n",
    "    y_test = test_df[label_column]\n",
    "    dmatrix_test = xgb.DMatrix(X_test)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_proba = booster.predict(dmatrix_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\nConfusion Matrix (Test Data):\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report (Test Data):\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Display feature importances from the final model\n",
    "    feature_scores = booster.get_score(importance_type='weight')\n",
    "    if feature_scores:\n",
    "        feature_importances = pd.Series(feature_scores).sort_values(ascending=False)\n",
    "        print(\"\\nFeature Importances:\")\n",
    "        print(feature_importances)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize Ray\n",
    "    # ray.init() # Use this if not connecting to an existing cluster\n",
    "\n",
    "    raw_data_filename = '3G_cdr_data.csv'\n",
    "    model_output_filename = 'fraud_detection_model_xgb_ray.json'\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nReading '{raw_data_filename}' with Ray Data...\")\n",
    "        raw_ds = ray.data.read_csv(raw_data_filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading raw data file: {e}\")\n",
    "        exit()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Perform feature engineering on the *entire* dataset first.\n",
    "    features_ds = feature_engineering_ray(raw_ds)\n",
    "\n",
    "    # 2. Split the *engineered* data into three sets.\n",
    "    train_ds, valid_ds, test_ds = prepare_data(features_ds)\n",
    "\n",
    "    # 3. Train the model on the correctly engineered training and validation sets.\n",
    "    fraud_model_booster = train_fraud_detection_model_xgb_ray(train_ds, valid_ds)\n",
    "\n",
    "    # 4. Evaluate the model and save the final result.\n",
    "    if fraud_model_booster:\n",
    "        evaluate_model(fraud_model_booster, test_ds)\n",
    "        \n",
    "        fraud_model_booster.save_model(model_output_filename)\n",
    "        print(f\"\\nTrained XGBoost model saved to '{model_output_filename}'\")\n",
    "    else:\n",
    "        print(\"Model training failed, so no evaluation or saving was performed.\")\n",
    "\n",
    "    print(f\"\\nProcess complete in {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "    # ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2687c4-22b2-472b-bada-83e7ddfcce09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
