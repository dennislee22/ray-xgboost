{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63a5d1f5-741f-4fc9-89f0-c5f8913d0161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping addon with invalid or excluded ID: {'type': 'cmladdon', 'path': '/runtime-addons/cmladdon-2.0.49-b279', 'spec': '\\nenv:\\n  MLFLOW_TRACKING_URI: cml://localhost\\n  MLFLOW_REGISTRY_URI: cml://localhost\\n  PYTHONPATH: ${PYTHONPATH}:/opt/cmladdons/python/site-customize\\n  R_LIBS_SITE: ${R_LIBS_SITE}:/opt/cmladdons/r/libs\\npaths:\\n  - /opt/cmladdons', 'version': '', 'id': -1}\n",
      "2025-07-15 11:07:44,460\tINFO usage_lib.py:467 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
      "2025-07-15 11:07:44,460\tINFO scripts.py:971 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m10.42.1.93\u001b[22m\n",
      "2025-07-15 11:07:56,667\tSUCC scripts.py:1007 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-07-15 11:07:56,668\tSUCC scripts.py:1008 -- \u001b[32mRay runtime started.\u001b[39m\n",
      "2025-07-15 11:07:56,668\tSUCC scripts.py:1009 -- \u001b[32m--------------------\u001b[39m\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1011 -- \u001b[36mNext steps\u001b[39m\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1014 -- To add another node to this Ray cluster, run\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1017 -- \u001b[1m  ray start --address='10.42.1.93:6379'\u001b[22m\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1026 -- To connect to this Ray cluster:\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1028 -- \u001b[35mimport\u001b[39m\u001b[26m ray\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1029 -- ray\u001b[35m.\u001b[39m\u001b[26minit()\n",
      "2025-07-15 11:07:56,668\tINFO scripts.py:1041 -- To submit a Ray job using the Ray Jobs CLI:\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1042 -- \u001b[1m  RAY_ADDRESS='http://127.0.0.1:8100' ray job submit --working-dir . -- python my_script.py\u001b[22m\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1051 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html \n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1055 -- for more information on submitting Ray jobs to the Ray cluster.\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1060 -- To terminate the Ray runtime, run\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1061 -- \u001b[1m  ray stop\u001b[22m\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1064 -- To view the status of the cluster, use\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1065 --   \u001b[1mray status\u001b[22m\u001b[26m\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1069 -- To monitor and debug Ray, view the dashboard at \n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1070 --   \u001b[1m127.0.0.1:8100\u001b[22m\u001b[26m\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1077 -- \u001b[4mIf connection to the dashboard fails, check your firewall settings and network configuration.\u001b[24m\n",
      "2025-07-15 11:07:56,669\tINFO scripts.py:1181 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
      "2025-07-15 11:07:56,670\tINFO scripts.py:1182 -- This command will now block forever until terminated by a signal.\n",
      "2025-07-15 11:07:56,670\tINFO scripts.py:1185 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, sys, os\n",
    "import cml.workers_v1 as workers\n",
    "\n",
    "DASHBOARD_PORT = os.environ['CDSW_READONLY_PORT']\n",
    "DASHBOARD_IP = os.environ['CDSW_IP_ADDRESS']\n",
    "\n",
    "command = \"ray start --head --block --include-dashboard=true --dashboard-port=$CDSW_READONLY_PORT --num-gpus=0 &\" \n",
    "\n",
    "subprocess.run(command, shell = True, executable=\"/bin/bash\")\n",
    "\n",
    "with open(\"RAY_HEAD_IP\", 'w') as output_file:\n",
    "    output_file.write(DASHBOARD_IP)\n",
    "            \n",
    "ray_head_addr = DASHBOARD_IP + ':6379'\n",
    "ray_url = f\"ray://{DASHBOARD_IP}:10001\" \n",
    "worker_start_cmd = f\"!ray start --block --address={ray_head_addr}\"\n",
    "\n",
    "ray_workers = workers.launch_workers(\n",
    "    n=5, \n",
    "    cpu=1, \n",
    "    memory=16,\n",
    "    nvidia_gpu=0,\n",
    "    code=worker_start_cmd,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4016967c-5f46-4359-91f9-645e2acb7cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:09:40,990\tINFO worker.py:1723 -- Connecting to existing Ray cluster at address: 10.42.1.93:6379...\n",
      "2025-07-15 11:09:41,025\tINFO worker.py:1908 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8100 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading 'cdr_data.csv' with Ray Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:09:51,089\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_2_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training, validation, and test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:09:51,367\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_2_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:09:51,368\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_2_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV] -> AllToAllOperator[RandomShuffle] -> AggregateNumRows[AggregateNumRows]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32ef5b418d74571a73194b0de4e4032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442a1f7006dd45ac81e6d5017a06acca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadCSV->SplitBlocks(384) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80cbc417f6d64cd1a84c599368863d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1cda377a3a4e07ade40f2e522ef611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e972fbe64da4afa8ea3795e96a772af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f06fad0550748f18dc3827492e1534c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- AggregateNumRows 5:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:10:39,489\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_2_0 execution finished in 48.11 seconds\n",
      "2025-07-15 11:10:39,549\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_1_0\n",
      "2025-07-15 11:10:39,568\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_1_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:10:39,571\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_1_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadCSV] -> AllToAllOperator[RandomShuffle]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004865b1c7584b02b0549b7189decd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b51cd3d2a694b8897d554dc012a9cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadCSV->SplitBlocks(384) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdd0cf302d244449cb45f806f14112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35938fa216e7452d97597ea015489856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f11fbc881b46689799824a459b5f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:10:59,311\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_1_0 execution finished in 19.74 seconds\n",
      "2025-07-15 11:10:59,720\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_5_0\n",
      "2025-07-15 11:10:59,725\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_5_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:10:59,727\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_5_0: InputDataBuffer[Input] -> AllToAllOperator[RandomShuffle]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d254df5a55e457ca8328a26376febf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e9a2788b4c412fb2e8c88dd8b015b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- RandomShuffle 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634ed8e0cbe248a4ac2348498c8ed194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b55d2c4b713427c8d2340b68b1f9173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:11:01,135\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_5_0 execution finished in 1.40 seconds\n",
      "/home/cdsw/.local/lib/python3.10/site-packages/ray/data/dataset.py:1419: UserWarning: Use 'expr' instead of 'fn' when possible for performant filters.\n",
      "  warnings.warn(\n",
      "2025-07-15 11:11:01,315\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_17_0\n",
      "2025-07-15 11:11:01,327\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_17_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:11:01,330\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_17_0: InputDataBuffer[Input] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)->Filter(<lambda>)] -> AggregateNumRows[AggregateNumRows]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 3000917\n",
      "Validation set size: 643054\n",
      "Test set size: 643054\n",
      "Performing feature engineering...\n",
      "Performing feature engineering...\n",
      "Performing feature engineering...\n",
      "\n",
      "Training the XGBoost model with Ray Train...\n",
      "Calculating scale_pos_weight from training data for class imbalance...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ac8059aacb40109488dd2d3bcec7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9db99b17abc45d3bcfe376e5137eab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31feac3408344691865a2410fd37e491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3414851089a4a29bea9afcf526e004e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b01bfd8389c44288657e4d8a4cfc9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbe37d0a92248cfaf6462387c86704c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)->Filter(<lambda>) 5: 0.00 row [00:00, ? r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560ac6a96eaa45f29148fcbb127746f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- AggregateNumRows 6:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:11:01,475\tWARNING progress_bar.py:120 -- Truncating long operator name to 100 characters. To disable this behavior, set `ray.data.DataContext.get_current().DEFAULT_ENABLE_PROGRESS_BAR_NAME_TRUNCATION = False`.\n",
      "2025-07-15 11:11:11,606\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_17_0 execution finished in 10.27 seconds\n",
      "2025-07-15 11:11:11,645\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_19_0\n",
      "2025-07-15 11:11:11,654\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_19_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:11:11,656\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_19_0: InputDataBuffer[Input] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)->Filter(<lambda>)] -> AggregateNumRows[AggregateNumRows]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b609da35a36472d87351b23e7e89231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74544e1c8e594d60afb2b275107963df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdb6b944e0d4b0e9208aca150543e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a2c764073740c7b05ec62abbd954fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612be335cc0141a2b1879cd3a2b7e943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7b4b8c8ced400995cd27e4ca886049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)->Filter(<lambda>) 5: 0.00 row [00:00, ? r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60df81daebfe42499840b9bce4cd84e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- AggregateNumRows 6:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:11:21,358\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_19_0 execution finished in 9.69 seconds\n",
      "2025-07-15 11:11:21,573\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight determined to be: 19.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:11:22,360\tWARNING tune_controller.py:2132 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (211 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent pending trials.\n",
      "2025-07-15 11:11:22,367\tWARNING tune_controller.py:2132 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (211 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent pending trials.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:22 (running for 00:00:00.20)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:27 (running for 00:00:05.25)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:32 (running for 00:00:10.31)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:37 (running for 00:00:15.37)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 PENDING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:42 (running for 00:00:20.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:47 (running for 00:00:25.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m Started distributed worker processes: \n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m - (node_id=5b95818d9f030342332c29f4928293bccf49d5216a1cd1fef3aec377, ip=10.42.3.72, pid=4512) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m - (node_id=5b95818d9f030342332c29f4928293bccf49d5216a1cd1fef3aec377, ip=10.42.3.72, pid=4513) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m - (node_id=5b95818d9f030342332c29f4928293bccf49d5216a1cd1fef3aec377, ip=10.42.3.72, pid=4511) world_rank=2, local_rank=2, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m - (node_id=5b95818d9f030342332c29f4928293bccf49d5216a1cd1fef3aec377, ip=10.42.3.72, pid=4515) world_rank=3, local_rank=3, node_rank=0\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m - (node_id=5b95818d9f030342332c29f4928293bccf49d5216a1cd1fef3aec377, ip=10.42.3.72, pid=4514) world_rank=4, local_rank=4, node_rank=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:52 (running for 00:00:30.59)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:11:58 (running for 00:00:35.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4512, ip=10.42.3.72)\u001b[0m [11:11:59] Task [xgboost.ray-rank=00000000]:9d84c89a15f8a22c00bde6bc01000000 got rank 0\n",
      "\u001b[36m(SplitCoordinator pid=4856, ip=10.42.3.72)\u001b[0m Registered dataset logger for dataset train_20_0\n",
      "\u001b[36m(SplitCoordinator pid=4856, ip=10.42.3.72)\u001b[0m Starting execution of Dataset train_20_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4856, ip=10.42.3.72)\u001b[0m Execution plan of Dataset train_20_0: InputDataBuffer[Input] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)] -> OutputSplitter[split(5, equal=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf32ee3bbd234dd6b4a2d7e0aae416e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b37290391a4358b99e20234e657c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) - Sort 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3da744399d545968452999aed98f47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) Sort Sample 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e3bc82d61f4294ab16cf4358e795a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd54d3303f143e38c66149ab8b4af26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6431bdc997e84b3d8e9cb2b92eb2ae76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) - MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>) 5: 0.00 row [00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d289508ab5f4337a966217387d25e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4856, ip=10.42.3.72) - split(5, equal=True) 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:03 (running for 00:00:40.70)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:08 (running for 00:00:45.75)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:13 (running for 00:00:50.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:18 (running for 00:00:55.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:23 (running for 00:01:00.91)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:28 (running for 00:01:05.96)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:33 (running for 00:01:11.02)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:38 (running for 00:01:16.07)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:43 (running for 00:01:21.13)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:48 (running for 00:01:26.19)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:53 (running for 00:01:31.24)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:12:58 (running for 00:01:36.29)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:03 (running for 00:01:41.35)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:08 (running for 00:01:46.40)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:13 (running for 00:01:51.47)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:18 (running for 00:01:56.52)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:23 (running for 00:02:01.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:29 (running for 00:02:06.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:34 (running for 00:02:11.69)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:39 (running for 00:02:16.74)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:44 (running for 00:02:21.80)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:49 (running for 00:02:26.85)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:54 (running for 00:02:31.93)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:13:59 (running for 00:02:36.98)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SplitCoordinator pid=4856, ip=10.42.3.72)\u001b[0m ✔️  Dataset train_20_0 execution finished in 123.57 seconds\n",
      "\u001b[36m(RayTrainWorker pid=4514, ip=10.42.3.72)\u001b[0m [11:11:59] Task [xgboost.ray-rank=00000004]:8c09f59564e2a4d97305afa801000000 got rank 4\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-15 11:14:04 (running for 00:02:42.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4512, ip=10.42.3.72)\u001b[0m Registered dataset logger for dataset dataset_24_0\n",
      "\u001b[36m(SplitCoordinator pid=4857, ip=10.42.3.72)\u001b[0m Starting execution of Dataset valid_21_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "\u001b[36m(SplitCoordinator pid=4857, ip=10.42.3.72)\u001b[0m Execution plan of Dataset valid_21_0: InputDataBuffer[Input] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)] -> OutputSplitter[split(5, equal=True)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf6ff245e5b46e18a0f6aa91136e7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c087477dac4b268acc04aa006d5d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) - Sort 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a3624b441d4b939d1d883c31e3841f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) Sort Sample 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f26aac6fe041269e50737895721942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c2b701fe5f4bc5b8a39456e19cd50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3256185dbe4ff5a5b2b17f54bc2e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) - MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>) 5: 0.00 row [00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e21c916b264363a19554408d5d11fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(pid=4857, ip=10.42.3.72) - split(5, equal=True) 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-15 11:14:09 (running for 00:02:47.11)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2025-07-15 11:14:14 (running for 00:02:52.17)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(RayTrainWorker pid=4512, ip=10.42.3.72)\u001b[0m Registered dataset logger for dataset dataset_28_0\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(SplitCoordinator pid=4857, ip=10.42.3.72)\u001b[0m ✔️  Dataset valid_21_0 execution finished in 10.24 seconds\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:16] [0]\ttrain-logloss:0.43757\ttrain-error:0.00000\tvalid-logloss:0.43897\tvalid-error:0.00005\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:16] [1]\ttrain-logloss:0.29638\ttrain-error:0.00000\tvalid-logloss:0.29788\tvalid-error:0.00005\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:16] [2]\ttrain-logloss:0.20741\ttrain-error:0.00000\tvalid-logloss:0.21508\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:16] [3]\ttrain-logloss:0.14788\ttrain-error:0.00000\tvalid-logloss:0.15392\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:16] [4]\ttrain-logloss:0.10669\ttrain-error:0.00000\tvalid-logloss:0.11163\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:17] [5]\ttrain-logloss:0.07757\ttrain-error:0.00000\tvalid-logloss:0.08552\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:17] [6]\ttrain-logloss:0.05671\ttrain-error:0.00000\tvalid-logloss:0.06291\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:17] [7]\ttrain-logloss:0.04162\ttrain-error:0.00000\tvalid-logloss:0.04657\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:17] [8]\ttrain-logloss:0.03065\ttrain-error:0.00000\tvalid-logloss:0.03514\tvalid-error:0.00000\n",
      "\u001b[36m(XGBoostTrainer pid=4438, ip=10.42.3.72)\u001b[0m [11:14:17] [9]\ttrain-logloss:0.02262\ttrain-error:0.00000\tvalid-logloss:0.02831\tvalid-error:0.00000\n",
      "\u001b[36m(RayTrainWorker pid=4512, ip=10.42.3.72)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/cdsw/ray_results/XGBoostTrainer_2025-07-15_11-11-21/XGBoostTrainer_703d9_00000_0_2025-07-15_11-11-22/checkpoint_000000)\n",
      "2025-07-15 11:14:18,416\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/cdsw/ray_results/XGBoostTrainer_2025-07-15_11-11-21' in 0.0563s.\n",
      "2025-07-15 11:14:18,424\tINFO tune.py:1041 -- Total run time: 176.85 seconds (175.99 seconds for the tuning loop).\n",
      "2025-07-15 11:14:18,497\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_33_0\n",
      "2025-07-15 11:14:18,505\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_33_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:14:18,506\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_33_0: InputDataBuffer[Input] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)] -> LimitOperator[limit=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2025-07-15 11:14:18 (running for 00:02:56.05)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 6.0/192 CPUs, 0/0 GPUs\n",
      "Result logdir: /tmp/ray/session_2025-07-15_11-07-44_461720_157/artifacts/2025-07-15_11-11-21/XGBoostTrainer_2025-07-15_11-11-21/driver_artifacts\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "\n",
      "\n",
      "\n",
      "Model Training Complete.\n",
      "\n",
      "--- Model Evaluation on Unseen Test Data ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0783677afb9451ebf5425056ae2b682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2861e774e6134b928a7daa9188ad11b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff92cd3ea5b41da97b4d5e932940aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a831cc71f174505a676524e2950839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7a7820e29b4d5c8b6c6f0f337f1f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4072166a3bf46d2ac08f6d408d231cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>) 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df64fce0f1664dbeb26af0d59c56d6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- limit=1 6: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:14:22,440\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_33_0 execution finished in 3.93 seconds\n",
      "2025-07-15 11:14:22,461\tINFO logging.py:295 -- Registered dataset logger for dataset dataset_32_0\n",
      "2025-07-15 11:14:22,466\tINFO streaming_executor.py:117 -- Starting execution of Dataset dataset_32_0. Full logs are in /tmp/ray/session_2025-07-15_11-07-44_461720_157/logs/ray-data\n",
      "2025-07-15 11:14:22,466\tINFO streaming_executor.py:118 -- Execution plan of Dataset dataset_32_0: InputDataBuffer[Input] -> AllToAllOperator[Sort] -> TaskPoolMapOperator[MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>)]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc62ceae8bf44d0f9a3805db0665cd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d50ad09355a433c98b0301d96c89b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Sort 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b31155cf444cb9b56aeecca9282f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sort Sample 2:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f568ffc09942ea8ea24ffb5ac88f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 3:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14d977ceea84104a4eed6278b55dd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 4:   0%|          | 0.00/1.00 [00:00<?, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c7287946d445e19f80dc032e27a586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(calculate_all_features_for_group)->MapBatches(<lambda>) 5: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 11:14:26,937\tINFO streaming_executor.py:227 -- ✔️  Dataset dataset_32_0 execution finished in 4.46 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Test Data):\n",
      "[[18981     0]\n",
      " [    0  1000]]\n",
      "\n",
      "Classification Report (Test Data):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     18981\n",
      "        True       1.00      1.00      1.00      1000\n",
      "\n",
      "    accuracy                           1.00     19981\n",
      "   macro avg       1.00      1.00      1.00     19981\n",
      "weighted avg       1.00      1.00      1.00     19981\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "total_calls             9.0\n",
      "outgoing_call_ratio     3.0\n",
      "avg_duration            3.0\n",
      "nocturnal_call_ratio    3.0\n",
      "dtype: float64\n",
      "\n",
      "Trained XGBoost model saved to 'fraud_detection_model_xgb_ray.json'\n",
      "\n",
      "Process complete in 276.25 seconds.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.data import Dataset\n",
    "from ray.train import ScalingConfig\n",
    "from ray.train.xgboost import XGBoostTrainer\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import os\n",
    "\n",
    "from ray.data import Dataset\n",
    "\n",
    "def calculate_all_features_for_group(group_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calculates aggregated features for a single user (a group of records).\"\"\"\n",
    "    group_df['is_fraud'] = group_df['is_fraud'].astype(bool)\n",
    "    nocturnal_hours = (group_df['hour_of_day'] >= 22) | (group_df['hour_of_day'] <= 6)\n",
    "    features = {\n",
    "        'total_calls': len(group_df),\n",
    "        'outgoing_call_ratio': (group_df['call_direction'] == 'outgoing').mean(),\n",
    "        'avg_duration': group_df['duration'].mean(),\n",
    "        'std_duration': group_df['duration'].std(),\n",
    "        'nocturnal_call_ratio': nocturnal_hours.mean(),\n",
    "        'mobility': group_df['cell_tower'].nunique(),\n",
    "        'is_fraud': group_df['is_fraud'].iloc[0]\n",
    "    }\n",
    "    return pd.DataFrame([features], index=[group_df['msisdn'].iloc[0]])\n",
    "\n",
    "def feature_engineering_ray(ds: ray.data.Dataset) -> ray.data.Dataset:\n",
    "    \"\"\"Performs feature engineering on the raw call data using Ray Data.\"\"\"\n",
    "    print(\"Performing feature engineering...\")\n",
    "    user_features_ds = ds.groupby('msisdn').map_groups(\n",
    "        calculate_all_features_for_group\n",
    "    )\n",
    "    return user_features_ds\n",
    "\n",
    "def prepare_data(dataset: Dataset) -> tuple[Dataset, Dataset, Dataset]:\n",
    "    \"\"\"Splits the dataset into train (70%), validation (15%), and test (15%) sets.\"\"\"\n",
    "    print(\"Splitting data into training, validation, and test sets...\")\n",
    "    seed = 42\n",
    "    train_dataset, rest = dataset.train_test_split(test_size=0.3, shuffle=True, seed=seed)\n",
    "    valid_dataset, test_dataset = rest.train_test_split(test_size=0.5, shuffle=True, seed=seed)\n",
    "    \n",
    "    print(f\"Train set size: {train_dataset.count()}\")\n",
    "    print(f\"Validation set size: {valid_dataset.count()}\")\n",
    "    print(f\"Test set size: {test_dataset.count()}\")\n",
    "    \n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "def train_fraud_detection_model_xgb_ray(train_ds: ray.data.Dataset, valid_ds: ray.data.Dataset):\n",
    "    \"\"\"Trains a fraud detection model using XGBoost with Ray Train.\"\"\"\n",
    "    print(\"\\nTraining the XGBoost model with Ray Train...\")\n",
    "\n",
    "    train_ds = train_ds.map_batches(lambda df: df.fillna(0), batch_format=\"pandas\")\n",
    "    valid_ds = valid_ds.map_batches(lambda df: df.fillna(0), batch_format=\"pandas\")\n",
    "\n",
    "    print(\"Calculating scale_pos_weight from training data for class imbalance...\")\n",
    "    num_fraud = train_ds.filter(lambda row: row[\"is_fraud\"] == True).count()\n",
    "    num_non_fraud = train_ds.filter(lambda row: row[\"is_fraud\"] == False).count()\n",
    "\n",
    "    if num_fraud > 0 and num_non_fraud > 0:\n",
    "        scale_pos_weight = num_non_fraud / num_fraud\n",
    "        print(f\"scale_pos_weight determined to be: {scale_pos_weight:.2f}\")\n",
    "    else:\n",
    "        scale_pos_weight = 1.0\n",
    "        print(f\"Warning: Insufficient classes to calculate scale_pos_weight. Defaulting to 1.0.\")\n",
    "\n",
    "    xgb_params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"scale_pos_weight\": scale_pos_weight,\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    label_column = 'is_fraud'\n",
    "    \n",
    "    trainer = XGBoostTrainer(\n",
    "        scaling_config=ScalingConfig(num_workers=5, use_gpu=False),\n",
    "        label_column=label_column,\n",
    "        params=xgb_params,\n",
    "        datasets={\"train\": train_ds, \"valid\": valid_ds},\n",
    "    )\n",
    "\n",
    "    result = trainer.fit()\n",
    "    print(\"\\nModel Training Complete.\")\n",
    "    \n",
    "    # Corrected: Use get_best_checkpoint method\n",
    "    best_checkpoint = result.get_best_checkpoint(metric=\"valid-logloss\", mode=\"min\")\n",
    "    \n",
    "    if best_checkpoint:\n",
    "        with best_checkpoint.as_directory() as checkpoint_dir:\n",
    "            #model_path = os.path.join(checkpoint_dir, \"model.xgb\")\n",
    "            model_path = os.path.join(checkpoint_dir, \"model.ubj\")\n",
    "            if os.path.exists(model_path):\n",
    "                booster = xgb.Booster()\n",
    "                booster.load_model(model_path)\n",
    "                return booster\n",
    "    print(\"Could not load a model from checkpoint.\")\n",
    "    return None\n",
    "\n",
    "def evaluate_model(booster: xgb.Booster, test_ds: ray.data.Dataset):\n",
    "    \"\"\"Evaluates the trained model on the unseen test dataset.\"\"\"\n",
    "    print(\"\\n--- Model Evaluation on Unseen Test Data ---\")\n",
    "\n",
    "    test_ds = test_ds.map_batches(lambda df: df.fillna(0), batch_format=\"pandas\")\n",
    "\n",
    "    feature_columns = [col for col in test_ds.columns() if col != 'is_fraud']\n",
    "    label_column = 'is_fraud'\n",
    "    \n",
    "    test_df = test_ds.to_pandas()\n",
    "    \n",
    "    if test_df.empty:\n",
    "        print(\"Test dataset is empty. Cannot evaluate.\")\n",
    "        return\n",
    "\n",
    "    X_test = test_df[feature_columns]\n",
    "    y_test = test_df[label_column]\n",
    "    dmatrix_test = xgb.DMatrix(X_test)\n",
    "    \n",
    "    y_pred_proba = booster.predict(dmatrix_test)\n",
    "    y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "    print(\"\\nConfusion Matrix (Test Data):\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report (Test Data):\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    feature_scores = booster.get_score(importance_type='weight')\n",
    "    if feature_scores:\n",
    "        feature_importances = pd.Series(feature_scores).sort_values(ascending=False)\n",
    "        print(\"\\nFeature Importances:\")\n",
    "        print(feature_importances)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    raw_data_filename = 'cdr_data.csv'\n",
    "    model_output_filename = 'fraud_detection_model_xgb_ray.json'\n",
    "\n",
    "    try:\n",
    "        print(f\"\\nReading '{raw_data_filename}' with Ray Data...\")\n",
    "        raw_ds = ray.data.read_csv(\n",
    "            raw_data_filename,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading raw data file: {e}\")\n",
    "        exit()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Split data into three sets\n",
    "    train_raw_ds, valid_raw_ds, test_raw_ds = prepare_data(raw_ds)\n",
    "\n",
    "    # 2. Apply feature engineering to each split\n",
    "    train_features_ds = feature_engineering_ray(train_raw_ds)\n",
    "    valid_features_ds = feature_engineering_ray(valid_raw_ds)\n",
    "    test_features_ds = feature_engineering_ray(test_raw_ds)\n",
    "\n",
    "    # 3. Train the model\n",
    "    fraud_model_booster = train_fraud_detection_model_xgb_ray(train_features_ds, valid_features_ds)\n",
    "\n",
    "    # 4. Evaluate and save the final model\n",
    "    if fraud_model_booster:\n",
    "        evaluate_model(fraud_model_booster, test_features_ds)\n",
    "        \n",
    "        fraud_model_booster.save_model(model_output_filename)\n",
    "        print(f\"\\nTrained XGBoost model saved to '{model_output_filename}'\")\n",
    "    else:\n",
    "        print(\"Model training failed, so no evaluation or saving was performed.\")\n",
    "\n",
    "    print(f\"\\nProcess complete in {time.time() - start_time:.2f} seconds.\")\n",
    "    \n",
    "    # ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef3dc5-9861-4146-a684-47c40a9bc3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
